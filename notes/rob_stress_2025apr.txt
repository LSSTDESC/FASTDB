Plan :
  * Run kafka server in kubernetes namespace
      --> Verify basic functionality with post_kafka_message.py and read_kafka_messages.py in this directory

      (On the kafka server, or another workload that has the kafka
      install, can check basic functionality with:
      
         echo "<message>" | /opt/kafka/bin/kafka-console-producer.sh --bootstrap-server kafka:9092 --topic <topic>

         /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list

         /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server kafka:9092 \
            --topic <topic> --group <group> --from-beginning [--max-messages <n>] [--timeout-ms <dt>]

         /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --list
      )

  * Start with ELAsTiCC2 loaded into ppdb tables

  * Run a fakebroker that posts messages to stress_apr2025_n_brokermsg

  * Run a shell with brokerconsumer

  * Run a shell in which we'll run a projectsim alert sender to send out
    n days worth of alerts to topic stress_apr2025_n




OBSERVATIONS:
  * (PRELIMINARY) : project sim can send alerts at ~700Hz with 5
    reconstructor processes


======================================================================

BABY STEPS

* servers running; fakebroker listening to topic stress_apr2025_1

* Wipe out ppdb_alerts_sent table

* Run projectsim.py to send 0.1 days of alerts
   -> 17862 alerts in 24.14 seconds (740 Hz)
   -> Fakebroker seems to have basically kept up

* Run brokerconsumer under /fastdb with
    LOGDIR=$PWD/logs python services/brokerconsumer.py /code/notes/brokerconsumer_config.yaml

  ...something was up with my mongo install, not sure what, but when I
  recreated it it worked.

  Consumed 8724 messages, but then consumed no more.  Took about ~20
  seconds, so reading them as fast as ppdb_alerts was producing them.
  There are 35724 documents in the mongo collection, which is the expected
  number.

* Run python services/source_importer.py -p test -c fastdb_stress_4

  Created 11921 objects, 17862 sources, 0 forced sources.  Went fast.

  Ran a second time, created nothing.

  (There were no forced sources because no alerts from the first day of
  the survey would have had a chance to include any.)


...I think I'm ready to try to bulk process this.

Clean up by wiping out the mongodb collections, and cleaning out the
diasource, diaobject, and ppdb_alerts_sent tables.  rm everything from
/fastdb/logs


======================================================================
Full day stress test

* Restart the fakebroker to read from stress_apr2025_2 and write to
  stress_apr2025_2_brokermsg.

* Edit brokerconsumer_config.yaml to read topic
  stress_apr2025_2_brokermsg, write to collection
  stress_apr2025_2, groupid test-5 (a new one)

* On a shell, run

    LOGDIR=$PWD/logs nohup python services/brokerconsumer.py /code/notes/brokerconsumer_config.yaml gratutious \
         < /dev/null > logs/brokerconsumer.out 2>&1 &

* On a different shell, run

    nohup python services/projectsim.py -t stress_apr2025_2 -a 1 -l 1000 --do \
        < /dev/null > logs/projectsim.out 2>&1 &

* Watch
    ...alert sender started at ~500Hz, after 75444 alerts claimed
       700Hz.  Took 107 seconds to send it all

    ...brokerconsumer seems to be keeping up with fakebroker.  (It tires
       to consume 1000 messages each step, is semetimes timing out with
       a few hundred.)  Took 252s to injest it all, but I think
       fakebroker was the delay, not brokerconsumer.  (More
       investigation needed.)
     
    ...!!!fakebroker seems to be getting more messages than were
       originally sent out! ... no, wait, the count its giving
       is the count of classifications its sent, not the count
       of alerts it got.  Logging issue.
      
* Run
     time python services/source_importer.py -p test -c stress_apr2025_2

     Imported 36387 objects, 75444 sources, 0 forced sources in 20s.

   ...need to put in some timings inside it to diagnose where it spends
      its time.

    
SECOND DAY

Run it all again (leave fakebroker running) to do the second day.

  ...happily, brokerconsumer, when started, saw no messages, so kafka
     topic offsets were remembered.

  ...alert sending more like 300Hz.  Wait, going up.  Ended at 140s for
     75606 alerts (540Hz).

  ...brokerconsumer sleeps sometimes, indicates fakebroker is the one
     not keeping up.  Brokerconsumer injested 151212 (right number)
     messages over 525 seconds.

  ...source_importer imported 22453 objects, 75606 sources, 33517 forced
     sources in 30s.

Basic functionality looks good.  Think about increasing the fakebroker's
message chunk grab size thingy to see if it makes it go faster.  (Right
now it tries to ingest 100 alerts at a time; try making it 1000.)


THIRD DAY

Increase fakebroker batch size to 1000 (from 100).  Point it at topic
stress_apr2025_3, have it write to stress_apr2025_3_brokermsg.  Edit
brokerconsumer_config.yaml to look at this brokermsg topic, use mongodb
collection stress_apr2025_3, and change
groupid to test-6.

  ...higher broker batch sizes seems to have helped its throughput,
     the broker consumer now usually has something to do.  It's working
     in 1000-message batches, and *usually* there are 1000 there.
     Somtimes fewer.

  ...alert sender sent 92416 alerts in 181s ( 511Hz )

  ...fakebroker's two classifiers classified them in 188s

  ...broker consumer consumed them all in 191s

  ...I failed to time it right, but source_importer took ~40s for:
       Imported 31246 objects, 92416 sources, 72226 forced sources


TEN MORE DAYS

Keep everything as is, run the following alert sender:

   nohup python services/projectsim.py -t stress_apr2025_3 -a 10 -l 1000 --do < /dev/null > logs/projectsim.out 2>&1 &

  ...the fake broker seemed to start out a bit slow (send_alerts
     producing at ~500Hz, each fakebroker classifier processed 4912
     alerts in ~98s, or ~50Hz.  Looks like the RandomSN classifier
     was taking more time... weird?  But then the fake broker hit
     the 10min timeout and server reconnect.  Since then, has
     classified 21000 alerts in 56s (375Hz).

  ...alert sender sent 589832 in 982s (601Hz)

  ...fake broker took ~2520s to classify them all

  ...broker consumer kept up with fake broker

  ...source_importer took 392s (6.5min) for:
        Imported 79440 objects, 589832 sources, 892983 forced sources

It occurs to me that I should separate the two classifiers of fakebroker
and have them both ingest the streams separately and send
classifications separately.  That way, the really fast one
(NugentClassifier) would keep up.  But, for now, try to make the random
classifier a bit faster by using a single numpy call to make all
necessary random numbers instead of repeated calls to python's
random.random.  (Still need a for loop to do all the calculations I was
doing.  I guess, since it's all BS anyway, I could change the
calculations to something faster.)  ...is it possible that this is
overhead in creating the Producer?  Hmm.

Or I could write them in C



ONE MORE DAY

Restart fakebroker with some changes, including time measurements.
Otherwise, keep everyting the same.  Send 1 more day of alerts:

   nohup python services/projectsim.py -t stress_apr2025_3 -a 1 -l 1000 --do < /dev/null > logs/projectsim.out 2>&1 &

   ...only 5705 alerts to go out, oh well.

   ...some huge lag getting alert sending started, first 1000 took 94
      sec, rest took antoher 10 sec

   ...DEBUG : error in fakebroker.  This means that some alerts will be
      dropped on the floor and not classified.  Oh well, this is all
      just timing tests anyway.


ONE MORE DAY

Restart fakebroker with some more changes, and run:

   nohup python services/projectsim.py -t stress_apr2025_3 -a 1 -l 1000 --do < /dev/null > logs/projectsim.out 2>&1 &

   ...had to do modify it to -a 3, because the first two days had no
      sources.  3rd day had 91333.  Sent them over 170s (538Hz).

   ...fake broker handled everything over 445s

   ...broker consumer got everything over 450s

   ...looks like everything I was worring about for the RandomSN
      classifier was all wrong.  The time doing the calculations is
      tiny.  Fakebroker is spending most of its time on the combination
      of fastrvro writing and confluent_kafka production, and
      (secondarily) fastavro reading.  fakebroker is running at ~400Hz
      as of right now.  Or so it claims.  I don't belelieve it, my
      numbers suggest it's more like 200Hz.  Does this mean that its
      actually spending half its time consuming the alerts it
      classifies?  Possible.  No, consume time is a tiny fraction of
      everything.  DUH.  No.  I'm stupid.  The classifiers are run
      serially, so of course each one has half the rate of the total!
      Now I'm tempted to use multiprocessing in my fake broker....  In
      any event, I suspect right now that most of the time is spent
      on avro parsing and unparsing.

  ...forgot to run source_importer, so the next one will have more to do



ONE MORE DAY

More logging to fakebroker.  Restart, run

   nohup python services/projectsim.py -t stress_apr2025_3 -a 1 -l 1000 --do < /dev/null > logs/projectsim.out 2>&1 &

   ...94414 alerts to send, going at ~500Hz again, took 177s.

   ...fakebroker took about 506 sec to do its thing, broker consumer
      kept up with fakebroker

   ...source_importer, which includes the sources from the previous day
      I forgot.  3m26s for:
        Imported 24561 objects, 191174 sources, 779011 forced sources



ONE MORE DAY

Made fakebroker multiprocessing.  Launch projectsim.py as before.

   ...27279 alerts to send.  Fakebroker seems to be keeping up, but I
      want to futz with it, so no full data here.

   ...did run source importer.  35s for:
            Imported 1523 objects, 27317 sources, 56582 forced sources


ONE MORE DAY

Had to do -a 2 in projectsim.py to get alerts to send

   ...23621 alerts to send.  Took 186.6s (632Hz)

   ...fakebroker handled them all in 40s.  (I started it after alerts
      were already going because of a crash bug the first time.)  So it
      kept up!

   ..source importer 20.3s for
       Imported 4387 objects, 23621 sources, 45389 forced sources



ONE MORE DAY


fakebroker error

107445 sources to send. after it was ~15000 in, I noticed it slowed down
for a bit.  fakebroker (once error fixed) no longer seems to be keeping
up.  I am perplexed.  Going to add more time granularity.

...off to do other things, shutting down.


